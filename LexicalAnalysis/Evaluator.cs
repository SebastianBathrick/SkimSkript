using SkimSkript.TokenManagement.Tokens;
using SkimSkript.TokenManagement;
using SkimSkript.Syntax;

namespace SkimSkript.LexicalAnalysis.Helpers
{
    /// <summary> Processes lexemes and generates tokens for use in the <see cref="TokenManagement.TokenContainer"/>. It includes 
    ///  functionality to build a reserved keyword trie, evaluate lexemes, and handle multi-word tokens. </summary>
    public class Evaluator
    {
        private TokenContainer _tokens = new TokenContainer();
        private CharacterNode _keywordTrieRoot = new CharacterNode();
        private List<(LexemeType type, string lexeme, int lineNumber)> _lexemeDataList;
        private int _lexemeIndex;

        /// <summary> Structure containing the tokens generated by using the lexeme data. </summary>
        public TokenContainer TokenContainer => _tokens;

        /// <param name="lexemeDataList"> List where each element contains a lexeme, its type, and the line number it was found on. </param>
        public Evaluator(List<(LexemeType type, string lexeme, int line)> lexemeDataList)
        {
            _lexemeDataList = lexemeDataList;
            BuildReservedWordsTrie();
            EvaluateLexemes();
        }

        /// <summary> Iterates through each lexeme and uses their data to create <see cref="Token"/>s 
        /// to populate an instance of <see cref="TokenManagement.TokenContainer"/>. </summary>
        private void EvaluateLexemes()
        {
            while (_lexemeDataList.Count != _lexemeIndex)
            {
                TokenType tokenType;
                var lexemeData = _lexemeDataList[_lexemeIndex];

                switch (_lexemeDataList[_lexemeIndex].type)
                {
                    case LexemeType.Alphanumeric: tokenType = TokenType.Identifier; break;
                    case LexemeType.NumericDecimal: tokenType = TokenType.Float; break;
                    case LexemeType.Numeric: tokenType = TokenType.Integer; break;
                    case LexemeType.Textual: tokenType = TokenType.String; break;
                    case LexemeType.Operator: tokenType = SyntaxSpec.operatorDict[lexemeData.lexeme]; break;
                    case LexemeType.Delimeter: tokenType = SyntaxSpec.GetDelimeterType(lexemeData.lexeme[0]); break;
                    default: tokenType = EvaluateAlphabetic(); break;
                }

                _tokens.Add(new Token(tokenType, lexemeData.lexeme, lexemeData.lineNumber));
                _lexemeIndex++;
            }
        }

        /// <summary> Determines if a lexeme or a continuous group of lexems form a reserved keyword/multi-word-token. </summary>
        private TokenType EvaluateAlphabetic()
        {
            TokenType lastReservedTokenType = TokenType.Identifier;
            CharacterNode? navNode = _keywordTrieRoot;
            bool isEvaluationComplete = false;
            int undefinedLexemesVisited = 0;

            do
            {
                string lexeme = _lexemeDataList[_lexemeIndex].lexeme;

                //Enter each char from a lexeme into the trie.
                for (int i = 0; i < lexeme.Length; i++)
                    if ((navNode = navNode.GetChild(lexeme[i])) == null)
                        break;

                bool isInvalidSearch = navNode == null;

                //If the type is not an identifier then all prev. visited lexemes are part of the same multi word token type.
                if (!isInvalidSearch && navNode.TokenType != TokenType.Identifier && navNode.TokenType != lastReservedTokenType && !isInvalidSearch)
                {
                    undefinedLexemesVisited = 0;
                    lastReservedTokenType = navNode.TokenType;
                }

                /*If the search was invalid or this was the final lexeme then the search cannot continue
                  The same goes for if the next lexeme is alphabetic (assuming it exists). Finally, as
                  we're moving onto a new lexeme, if the suspected TokenType does not contain a space
                  following where the search left off the search also cannot continue.*/
                if (!isInvalidSearch && IsNextLexemeAlphabetic() && (navNode = navNode.GetSpaceChild()) != null)
                {
                    _lexemeIndex++;
                    undefinedLexemesVisited++;
                }
                else
                    isEvaluationComplete = true;
            }
            while (!isEvaluationComplete);

            //Every lexeme that was visited and not identified with a TokenType will need to be re-evaluated.
            _lexemeIndex -= undefinedLexemesVisited;

            //If a reserved type was not found then an identifier will be returned.
            return lastReservedTokenType; 
        }

        /// <summary> Constructs trie that stores reserved words and their associated <see cref="TokenType"/>s. </summary>
        private void BuildReservedWordsTrie()
        {
            var reservedWords = SyntaxSpec.reservedWords;

            for (int i = 0; i < reservedWords.Length; i++)
            {
                CharacterNode navNode = _keywordTrieRoot;

                //For each char in a keyword add a node. Adding a special node if the char's a space.
                for (int j = 0; j < reservedWords[i].text.Length; j++)
                    navNode = reservedWords[i].text[j] != ' ' ? navNode.AddChild(reservedWords[i].text[j]) : navNode.AddSpaceChild();

                //Assign the TokenType to the leaf node containing the last character of the keyword.
                navNode.AssignTokenType(reservedWords[i].key);
            }
        }

        private bool IsNextLexemeAlphabetic() => _lexemeIndex != _lexemeDataList.Count - 1 && _lexemeDataList[_lexemeIndex + 1].type == LexemeType.Alphabetic;
    }
}
